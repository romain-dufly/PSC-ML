{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd134a95",
   "metadata": {},
   "source": [
    "# Tâche LEGO avec le modèle BERT\n",
    "\n",
    "Dans ce notebook, nous importons et entraînons sur la tâche LEGO un modèle BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6393dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertConfig, BertModel\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a8ea1",
   "metadata": {},
   "source": [
    "Nous fixons l'état des fonctions aléatoires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3c61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68652ba2",
   "metadata": {},
   "source": [
    "Ci-dessous, nous définissons diverses variables utiles par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7562d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# n_var: total number of variables in a chain\n",
    "# n_train_var: number of variables to provide supervision during training\n",
    "n_var, n_train_var = 6, 3\n",
    "\n",
    "# n_train: total number of training sequences\n",
    "# n_test: total number of test sequences\n",
    "n_train, n_test = n_var*10000, n_var*1000\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "# use_pretrained_transformer: whether to use a pretrained transformer as base model\n",
    "use_pretrained_transformer = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901aa78",
   "metadata": {},
   "source": [
    "Les fonctions ci-dessous servent à générer les données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1030b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(tokenizer, n_var, batch_size=100):\n",
    "    \n",
    "    batch = []\n",
    "    labels = []\n",
    "    clause_order = []\n",
    "    for _ in range(batch_size):\n",
    "        values = np.random.randint(0, 2, (n_var,))\n",
    "        var_idx = tuple(np.random.permutation(len(all_vars)))\n",
    "        vars = [all_vars[i] for i in var_idx]\n",
    "\n",
    "        # generate first sentence\n",
    "        clauses = []\n",
    "        clauses.append('%s = val %d , ' % (vars[0], values[0]))\n",
    "\n",
    "        for i in range(1, n_var):\n",
    "            modifier = 'val' if values[i] == values[i-1] else 'not'\n",
    "            clauses.append(' %s = %s %s , ' % (vars[i], modifier, vars[i-1]))\n",
    "            \n",
    "\n",
    "        sent = ''\n",
    "        label = []\n",
    "        \n",
    "        clause_idx = tuple(np.random.permutation(n_var))\n",
    "        sent += ''.join([clauses[idx] for idx in clause_idx])\n",
    "        label += [values[idx] for idx in clause_idx]\n",
    "        \n",
    "        \n",
    "        order = torch.zeros(1, n_var, n_var)\n",
    "        for i in range(n_var):\n",
    "            order[0, i, clause_idx[i]] = 1\n",
    "            \n",
    "        batch.append(tokenizer(sent, return_tensors='pt')['input_ids'])\n",
    "        labels.append(values)\n",
    "        clause_order.append(order)\n",
    "    return torch.cat(batch), torch.LongTensor(labels), torch.cat(clause_order)\n",
    "\n",
    "\n",
    "def make_lego_datasets(tokenizer, n_var, n_train, n_test, batch_size):\n",
    "    \n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_order = []\n",
    "\n",
    "    for i in range(n_train//100):\n",
    "        batch, labels, order = generate_data(tokenizer, n_var, 100)\n",
    "        train_data.append(batch)\n",
    "        train_labels.append(labels)\n",
    "        train_order.append(order)\n",
    "\n",
    "    x_train = torch.cat(train_data)\n",
    "    y_train = torch.cat(train_labels)\n",
    "    order_train = torch.cat(train_order)\n",
    "    \n",
    "    trainset = torch.utils.data.TensorDataset(x_train, y_train, order_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    test_order = []\n",
    "    for i in range(n_test//100):\n",
    "        batch, labels, order = generate_data(tokenizer, n_var, 100)\n",
    "        test_data.append(batch)\n",
    "        test_labels.append(labels)\n",
    "        test_order.append(order)\n",
    "\n",
    "    x_test = torch.cat(test_data)\n",
    "    y_test = torch.cat(test_labels)\n",
    "    order_test = torch.cat(test_order)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(x_test, y_test, order_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013140d7",
   "metadata": {},
   "source": [
    "Nous créons les données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7479cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28983/2070546095.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.cat(batch), torch.LongTensor(labels), torch.cat(clause_order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] a = not k, p = not c, z = val a, k = not n, n = val p, c = val 0, [SEP]\n",
      "[0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# specify tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# generate LEGO data loaders\n",
    "trainloader, testloader = make_lego_datasets(tokenizer, n_var, n_train, n_test, batch_size)\n",
    "\n",
    "# examine an example LEGO sequence\n",
    "seq, label, _ = trainloader.dataset[0]\n",
    "print(tokenizer.decode(seq))\n",
    "print(list(label.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd50c2b",
   "metadata": {},
   "source": [
    "Le modèle que nous allons utiliser est BERT, que nous importons à l'aide de transformers, et auquel nous rajoutons un classifieur à la suite pour obtenir un unique nombre réel.\n",
    "\n",
    "Un nombre positif en sortie indiquera une valeur $1$ pour la variable concernée, un nombre négatif la valeur $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4fd932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Wrapper on transformer model for token classification\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, base, d_model, tgt_vocab=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.base = base\n",
    "        self.classifier = nn.Linear(d_model, tgt_vocab)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        h = self.base(x)\n",
    "        out = self.classifier(h.last_hidden_state)\n",
    "        return out\n",
    "\n",
    "    \n",
    "if use_pretrained_transformer:\n",
    "    base = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "else:\n",
    "    config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "    base = BertModel(config)\n",
    "    \n",
    "model = Model(base, base.config.hidden_size)\n",
    "\n",
    "# Data parallel training\n",
    "model = nn.DataParallel(model.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536be7e6",
   "metadata": {},
   "source": [
    "Nous définissons deux fonctions permettant d'entraîner et de tester notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e5cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_var_pred = list(range(n_train_var))\n",
    "test_var_pred = list(range(n_var))\n",
    "\n",
    "# To save training information\n",
    "l_test_acc = []\n",
    "l_test_loss = []\n",
    "l_train_acc = []\n",
    "l_train_loss = []\n",
    "\n",
    "def train(print_acc=False):\n",
    "    global l_train_acc, l_train_loss\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = [0]*n_var\n",
    "    total = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels, order in trainloader:\n",
    "    \n",
    "        x = batch.cuda()\n",
    "        y = labels.cuda()\n",
    "        inv_order = order.permute(0, 2, 1).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        ordered_pred = torch.bmm(inv_order, pred[:, 1:-3:5, :]).squeeze()\n",
    "\n",
    "        loss = 0\n",
    "        for idx in train_var_pred:\n",
    "            loss += criterion(ordered_pred[:, idx], y[:, idx].float()) / len(train_var_pred)\n",
    "            total_loss += loss.item() / len(train_var_pred)\n",
    "    \n",
    "            correct[idx] += ((ordered_pred[:, idx]>0).long() == y[:, idx]).float().mean().item()\n",
    "            \n",
    "        total += 1\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc = [corr/total for corr in correct]\n",
    "\n",
    "    l_train_loss.append(total_loss / total)\n",
    "    l_train_acc.append(list(train_acc))\n",
    "    \n",
    "    return train_acc\n",
    "\n",
    "\n",
    "def test():\n",
    "    global l_test_acc, l_test_loss\n",
    "    \n",
    "    test_acc = []\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    correct = [0]*n_var\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, labels, order in testloader:\n",
    "    \n",
    "            x = batch.cuda()\n",
    "            y = labels.cuda()\n",
    "            inv_order = order.permute(0, 2, 1).cuda()\n",
    "            pred = model(x)\n",
    "            ordered_pred = torch.bmm(inv_order, pred[:, 1:-3:5, :]).squeeze()\n",
    "            \n",
    "            for idx in test_var_pred:\n",
    "                loss = criterion(ordered_pred[:, idx], y[:, idx].float())\n",
    "                total_loss += loss.item() / len(test_var_pred)\n",
    "                correct[idx] += ((ordered_pred[:, idx]>0).long() == y[:, idx]).float().mean().item()\n",
    "                          \n",
    "            total += 1\n",
    "        \n",
    "        test_acc = [corr/total for corr in correct]\n",
    "\n",
    "        l_test_loss.append(total_loss / total)\n",
    "        l_test_acc.append(list(test_acc))\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe84d96",
   "metadata": {},
   "source": [
    "Nous pouvons alors entraîner notre modèle (ici simplement sur un epoch pour vérifier le bon fonctionnement):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06001cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch:  1\n",
      "Test accuracy: \n",
      " [1.0, 1.0, 1.0, 0.49049998621145885, 0.5021666496992111, 0.4904999872048696]\n",
      "Time elapsed:  98.33883261680603\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"\\n Epoch: \", epoch)\n",
    "    start = time.time()\n",
    "\n",
    "    train()\n",
    "    print(\"Test accuracy: \\n\", test())\n",
    "    print(\"Time elapsed: \", time.time() - start)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b44d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
